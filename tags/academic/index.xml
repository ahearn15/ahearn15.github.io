<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Academic | Adam Hearn</title>
    <link>https://achearn.com/tags/academic/</link>
      <atom:link href="https://achearn.com/tags/academic/index.xml" rel="self" type="application/rss+xml" />
    <description>Academic</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Fri, 18 Dec 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://achearn.com/img/icon-192.png</url>
      <title>Academic</title>
      <link>https://achearn.com/tags/academic/</link>
    </image>
    
    <item>
      <title>Do institutions serve their geographic constituents? Evidence from student migratory patterns</title>
      <link>https://achearn.com/project/migration/</link>
      <pubDate>Fri, 18 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://achearn.com/project/migration/</guid>
      <description>&lt;p&gt;This RShiny web-app provides a resource for higher-ed stakeholders and researchers to investigate migration patterns of postsecondary learners.&lt;/p&gt;

&lt;p&gt;To enter the portal, click here: &lt;a href=&#34;https://adam-c-hearn.shinyapps.io/geo_ipeds//&#34; target=&#34;_blank&#34;&gt;https://adam-c-hearn.shinyapps.io/geo_ipeds//&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Higher-Ed Coronavirus Response in the Public Sector</title>
      <link>https://achearn.com/project/ds3/</link>
      <pubDate>Fri, 18 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://achearn.com/project/ds3/</guid>
      <description>

&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;

&lt;p&gt;Using a combination of data from the College Crisis Initiative (C2i), the Integrated Postsecondary Data System (IPEDS), and CDC coronavirus statistics, this paper investigates the factors which play significant roles in predicting Fall 2020 mode of instruction in the public, 4-year sector of higher education. Using principal components analysis (PCA), I am able to scale down nearly 30 institutional features to a handful of orthogonal vectors while maintaining relatively high predictive accuracy. Further, I find that the primary factors in predicting in-person instruction were state political leaning and intercollegiate athletics.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Working paper can be downloaded &lt;a href=&#34;https://achearn.com/files/research/highered_covid.pdf&#34;&gt;here.&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Generalized Synthetic Control Method: A Powerful ML Algorithm to Produce Counterfactual Estimates for Experimental Data</title>
      <link>https://achearn.com/post/gsc/</link>
      <pubDate>Sun, 15 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://achearn.com/post/gsc/</guid>
      <description>

&lt;h1 id=&#34;the-generalized-synthetic-control-method-a-powerful-ml-algorithm-to-produce-counterfactual-estimates-for-experimental-data&#34;&gt;The Generalized Synthetic Control Method: A Powerful ML Algorithm to Produce Counterfactual Estimates for Experimental Data&lt;/h1&gt;

&lt;p&gt;This post will cover the Generalized Synthetic Control method, a machine-learning algorithm that is lesser known within Data Science circles. Though this method is not often talked about, this quasi-experimental approach &lt;strong&gt;utilizes a robust latent-factor approach to synthetically produce counterfactuals for treated units&lt;/strong&gt;. As a result, we can gather coefficient estimates and standard errors to assess and evaluate treatment effects of policy interventions. A policy-relevant example using this method will be provided, with replication code available from my GitHub &lt;a href=&#34;https://github.com/ahearn15/ml_viz&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;why-generalized-synthetic-control&#34;&gt;Why Generalized Synthetic Control?&lt;/h2&gt;

&lt;p&gt;The fundamental challenge of causal inference is the parallel trends assumption. To quote &lt;a href=&#34;https://mycourses.aalto.fi/pluginfile.php/203124/mod_resource/content/1/Angrist%20%20Pischke.pdf&#34; target=&#34;_blank&#34;&gt;Angrist and Pischke (2009)&lt;/a&gt;, two-way fixed effects models produce non-biased, causal estimates only in &lt;strong&gt;“parallel worlds.”&lt;/strong&gt; This is a strong assumption to consider, as the unobserved counterfactual can rarely be produced using real data. For example, as a graduate student studying Data Science for Public Policy, it is impossible to know my post-graduation salary if I had &lt;strong&gt;not&lt;/strong&gt; attended graduate school. Luckily, we can rely on a combination of econometrics and machine learning to produce these counterfactual estimates while eliminating many of the confounding variables that may bias the typical difference-in-difference or fixed-effects regression models. This is where we turn to the Generalized Synthetic Control model.&lt;/p&gt;

&lt;h2 id=&#34;what-is-generalized-synthetic-control&#34;&gt;What is Generalized Synthetic Control?&lt;/h2&gt;

&lt;p&gt;The Generalized Synthetic Control Model &lt;strong&gt;“imputes counterfactuals for each treated unit using control group information based on a linear interactive fixed effects model that incorporates unit-specific intercepts interacted with time-varying coefficients”&lt;/strong&gt; (&lt;a href=&#34;https://www.cambridge.org/core/services/aop-cambridge-core/content/view/B63A8BD7C239DD4141C67DA10CD0E4F3/S1047198716000024a.pdf/generalized_synthetic_control_method_causal_inference_with_interactive_fixed_effects_models.pdf&#34; target=&#34;_blank&#34;&gt;Xu, 2017&lt;/a&gt;). Essentially, this supervised learning technique combines the interactive fixed-effects model and the synthetic control model, while employing a latent factor approach to provide valid, simulation-based uncertainty estimates.&lt;/p&gt;

&lt;p&gt;The model first estimates an interactive fixed-effect model using only the control group data, obtaining a fixed number of latent factors using a cross-validation approach. In other words, the algorithm selects the number of latent factors, &lt;em&gt;k&lt;/em&gt;, that &lt;strong&gt;minimizes the Mean Squared Prediction Error (MSPE)&lt;/strong&gt;. Next, the algorithm &lt;strong&gt;estimates factor loadings&lt;/strong&gt; for each treated unit. Lastly, the algorithm imputes &lt;strong&gt;treated counterfactuals&lt;/strong&gt; and standard errors based on the estimated factors and factor loadings. This is the step in which the &lt;em&gt;β&lt;/em&gt; coefficients are generated, while standard error estimates are calculated using bootstrapping techniques. These steps become much clearer once the visualizations are produced.&lt;/p&gt;

&lt;h2 id=&#34;case-study-the-test-optional-movement&#34;&gt;Case Study: The Test-Optional Movement&lt;/h2&gt;

&lt;p&gt;Since 2003, institutions have increasingly begun to drop the standardized-testing requirement for admission. In the 2003-04 admission cycle, over 75% of degree-granting, 4-year institutions required either the SAT or ACT upon application. However, in 2018-19, this number had dropped to just 48.3% with institutions increasingly shifting towards a policy of neither recommending nor requiring scores.&lt;/p&gt;

&lt;p&gt;Though most institutions who adopt this test-optional framework are under Private control, the Public sector has seen an increase in dropping test-requirements amidst the coronavirus pandemic. With the closing of many test-centers, many institutions are shifting away from the testing requirements in the 2021 admissions cycle. Given the uncertainty of the pandemic, however, it is possible that these policies may last longer than just one year. Using the Generalized Synthetic Control method, I can examine the post-implementation effects of this policy on low-income and minority enrollment.&lt;/p&gt;

&lt;p&gt;The theoretical framework claims that &lt;strong&gt;less-privileged students may find more difficulty in both preparing for standardized tests and taking the test itself.&lt;/strong&gt; Meanwhile, students who come from a more affluent background have greater access to both test-preparation and test-taking. By removing the burden of standardized test taking, the playing field can be more leveled regarding this aspect of the application. As a result, postsecondary access may become less challenging for underrepresented students. We can test this framework using the Generalized Synthetic Control method. Be sure to follow along using my replication code, available &lt;a href=&#34;https://github.com/ahearn15/ml_viz&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;dataset&#34;&gt;Dataset&lt;/h3&gt;

&lt;p&gt;The pre-processing of the data would be conducted just as we would if we were running a two-way fixed-effects regression with unique Year-ID pairs. In other words, we want a panel data format such as the following (note this is fake data):&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Year&lt;/th&gt;
&lt;th&gt;UnitID&lt;/th&gt;
&lt;th&gt;Test-Optional?&lt;/th&gt;
&lt;th&gt;Pct. Pell Enrollment&lt;/th&gt;
&lt;th&gt;Pct. Minority Enrollment&lt;/th&gt;
&lt;th&gt;…&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;2003&lt;/td&gt;
&lt;td&gt;367546&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;0.13&lt;/td&gt;
&lt;td&gt;0.39&lt;/td&gt;
&lt;td&gt;…&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;2003&lt;/td&gt;
&lt;td&gt;485656&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0.34&lt;/td&gt;
&lt;td&gt;0.45&lt;/td&gt;
&lt;td&gt;…&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;2003&lt;/td&gt;
&lt;td&gt;324635&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;0.09&lt;/td&gt;
&lt;td&gt;0.23&lt;/td&gt;
&lt;td&gt;…&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;…&lt;/td&gt;
&lt;td&gt;…&lt;/td&gt;
&lt;td&gt;…&lt;/td&gt;
&lt;td&gt;…&lt;/td&gt;
&lt;td&gt;..&lt;/td&gt;
&lt;td&gt;…&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;2018&lt;/td&gt;
&lt;td&gt;367546&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0.24&lt;/td&gt;
&lt;td&gt;0.37&lt;/td&gt;
&lt;td&gt;…&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;2018&lt;/td&gt;
&lt;td&gt;485656&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0.43&lt;/td&gt;
&lt;td&gt;0.67&lt;/td&gt;
&lt;td&gt;…&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;2018&lt;/td&gt;
&lt;td&gt;324635&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;0.13&lt;/td&gt;
&lt;td&gt;0.25&lt;/td&gt;
&lt;td&gt;…&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Once we have the data in this format, we’re ready to run the model. I’ll be conducting this algorithm with a sample of over 1000 4-year colleges and universities with data from the &lt;a href=&#34;https://nces.ed.gov/ipeds/&#34; target=&#34;_blank&#34;&gt;Integrated Postsecondary Education Data System (IPEDS)&lt;/a&gt;. Since the algorithm automatically selects the number of latent factors that minimize MSPE, we do not need to worry as much about control variables as these will be captured in the latent factors. However, I do include controls for institutional quality (acceptance rate, yield rate) and other measures that can influence postsecondary choice (tuition, avg. grant, enrollment).&lt;/p&gt;

&lt;h3 id=&#34;running-the-algorithm&#34;&gt;Running the Algorithm&lt;/h3&gt;

&lt;p&gt;With the GSC model, I can combat the parallel trends assumption of causal inference with high-confidence uncertainty estimates. Using GSC, there needs to be a balance between the number of years an institution is in the “pre-treatment” period as well as the number of years following the implementation. The higher the minimum value of pre-treatment values set as the parameter, the less biased the results will be. However, as this value increases, the number of observations decrease. With that tradeoff in mind, I find the best balance for both models in using 6 pre-treatment periods in the Pell model and 11 pre-treatment periods in the URM model. Further, this allows for both models to be examined with four-years of post-policy implementation effects.&lt;/p&gt;

&lt;h3 id=&#34;results&#34;&gt;Results&lt;/h3&gt;

&lt;p&gt;After running the algorithm, we get the following regression output:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Pct. full-time first-time &lt;br /&gt;students Pell&lt;/th&gt;
&lt;th&gt;Pct. degree-seeking first-time &lt;br /&gt;students minority&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Test-optional&lt;/td&gt;
&lt;td&gt;2.166***  &lt;br /&gt;(0.488)&lt;/td&gt;
&lt;td&gt;2.287***  &lt;br /&gt;(0.728)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Controls&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Institution/year fixed effects&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Unobserved Factors&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Observations&lt;/td&gt;
&lt;td&gt;1118&lt;/td&gt;
&lt;td&gt;1055&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Treated&lt;/td&gt;
&lt;td&gt;134&lt;/td&gt;
&lt;td&gt;119&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Control&lt;/td&gt;
&lt;td&gt;984&lt;/td&gt;
&lt;td&gt;936&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;em&gt;Note:&lt;/em&gt; Standard errors are based on parametric bootstraps (blocked at the institution level) of 2,500 times. Panel data from Title IV four-year degree-granting institutions. Years included are 2007-2017 in Column (1) and 2003-2017 in Column (2). *&lt;em&gt;p&lt;/em&gt;&amp;lt;0.05, **&lt;em&gt;p&lt;/em&gt;&amp;lt;0.01, ***&lt;em&gt;p&lt;/em&gt;&amp;lt;0.001.&lt;/p&gt;

&lt;h3 id=&#34;result-summary&#34;&gt;Result Summary&lt;/h3&gt;

&lt;p&gt;In short, I find that dropping the test-requirement is associated with roughly a 2-percentage point increase in both first-time Pell enrollment and underrepresented minority enrollment. These results are significant at the 99.9% confidence interval with standard errors based on 2,500 parametric bootstraps blocked at the institution level.&lt;/p&gt;

&lt;p&gt;A visualization of this algorithm is displayed below. &lt;strong&gt;The AUC between the treated (solid) and counterfactual (dashed) lines represent the beta estimate of the independent variable of interest (the policy-change)&lt;/strong&gt;. Note that we have less data on the Pell treated and counterfactual averages since this variable did not become available in the IPEDS universe until 2008.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;tca.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The visualization above helps tremendously to explain how the Generalized Synthetic Control algorithm works. It uses factor loadings to match “treated” institutions with “control” institutions prior to treatment, so &lt;strong&gt;we can see where the control group would end up had they implemented the policy&lt;/strong&gt;. In my experience as an econometrician, I believe the GSC algorithm creates a far more accurate measure of treatment effects than diff-in-diff or two-way fixed effects could by utilizing these factor weights and matching scores.&lt;/p&gt;

&lt;p&gt;Further, we can investigate the &lt;strong&gt;average treatment effects&lt;/strong&gt; on the institutions with the test-optional policy by period:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;att.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;These visualizations display the &lt;em&gt;β&lt;/em&gt; coefficients on the Y axis, the time relative to treatment on the X axis, and the 95% confidence interval in the shaded region. While the URM model is a bit nosier than the Pell model, we can still find &lt;strong&gt;significant treatment effects&lt;/strong&gt; in years 3 and 4 after policy implementation.&lt;/p&gt;

&lt;p&gt;The visualization from the Pell model also tells us that there may be placebo effects apparent. This means that institutions that dropped the test-requirement were seeing a significant increase in Pct. Pell enrollment prior to their treatment (especially in time &lt;em&gt;t&lt;/em&gt; – 2, where the null hypothesis that &lt;em&gt;β&lt;/em&gt; = 0 falls out of the 95% confidence interval). This makes the results spurious, and more challenging to attribute the increase in Pell enrollment to the test-optional policy. We can see that there are no placebo effects apparent in the Pct. Minority model.&lt;/p&gt;

&lt;h4 id=&#34;bootstrapped-standard-errors-visualization&#34;&gt;Bootstrapped Standard Errors Visualization&lt;/h4&gt;

&lt;p&gt;The area in the shaded region, the uncertainty estimates (aka the 95% confidence interval), change depending on the number of bootstraps. &lt;strong&gt;Bootstrapping is a data science method of resampling such that we eliminate sampling error in our estimates&lt;/strong&gt;. As we increase the number of bootstraps, the uncertainty estimates begin to stagnate. These are illustrated in the GIFS below.&lt;/p&gt;

&lt;p&gt;In this first GIF, we see the uncertainty estimates as we increase the number of bootstraps from 5 to 500:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;five_hundred.gif&#34; style=&#34;zoom:125%;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Here, we increase the number of bootstraps from 500 to 1000:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;one_thousand.gif&#34; style=&#34;zoom:125%;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;And lastly, just to drive the point home, here&amp;rsquo;s what our uncertainty estimates look like when we increase the bootstraps from 2,000 to 2,500 (the number I used in my main regression model):&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;two_thousand.gif&#34; style=&#34;zoom:125%;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;These GIFS illustrate the bootstrap resampling method, displaying the method in a way that clearly defines how the algorithm works under the hood.&lt;/p&gt;

&lt;h2 id=&#34;conclusions&#34;&gt;Conclusions&lt;/h2&gt;

&lt;p&gt;The generalized synthetic control method is a wonderful supervised-learning approach to produce counterfactual estimates, eliminating much of the confoundedness found in OLS and Fixed-Effects regression techniques. Further, the algorithm allows you to produce beautiful visualizations that aid tremendously in explaining how the algorithm works to a non-technical audience.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Isolating the Mechanisms Behind the Test-Optional Admissions Policy</title>
      <link>https://achearn.com/project/to/</link>
      <pubDate>Sat, 02 May 2020 00:00:00 +0000</pubDate>
      <guid>https://achearn.com/project/to/</guid>
      <description>

&lt;h3 id=&#34;abstract&#34;&gt;Abstract&lt;/h3&gt;

&lt;p&gt;The test-optional admissions policy is a growing tactic among four-year postsecondary institutions in the United States. While each institution decides individually whether or not to implement this policy, there has been little research done in evaluating these collective decisions across colleges and universities. By using machine learning algorithms across a range of institutions, I am able to uncover trends across schools that shine a light on why institutions may be heading in this direction. I find that the motives for implementing this policy may be different depending on the selectivity of the school.&lt;/p&gt;

&lt;h5 id=&#34;working-paper-can-be-downloaded-here-files-research-test-optional-pdf&#34;&gt;Working paper can be downloaded &lt;a href=&#34;https://achearn.com/files/research/test_optional.pdf&#34;&gt;here&lt;/a&gt;.&lt;/h5&gt;
</description>
    </item>
    
    <item>
      <title>Everyone Wants to Win: Even the Admissions Officers</title>
      <link>https://achearn.com/project/sensem/</link>
      <pubDate>Sat, 22 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://achearn.com/project/sensem/</guid>
      <description>

&lt;h3 id=&#34;abstract&#34;&gt;Abstract&lt;/h3&gt;

&lt;p&gt;Beginning each year around August, prospective college-goers begin filling out their applications to send off to institutions where they may end up for the next four years. The elements that go into this decision include the academic quality of the institution, the campus climate, and for some, the athletic successes the school has achieved in previous years. My research focuses on the last of these elements, as I assessed how collegiate athletics at the highest level impact postsecondary institutional metrics. In doing so, I found significant evidence that football success leads to increased applications, first-year enrollment, and reported SAT scores.&lt;/p&gt;

&lt;h5 id=&#34;working-paper-can-be-downloaded-here-files-research-hearn-april-20-pdf&#34;&gt;Working paper can be downloaded &lt;a href=&#34;https://achearn.com/files/research/Hearn_April_20.pdf&#34;&gt;here&lt;/a&gt;&lt;/h5&gt;
</description>
    </item>
    
  </channel>
</rss>
